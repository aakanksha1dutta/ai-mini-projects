{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import e, pow, log2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_libsvm_file(filename):\n",
    "    labels = []\n",
    "    features = []\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            elements = line.strip().split(' ')\n",
    "            labels.append(int(elements[0]))\n",
    "            feature_vector = {}\n",
    "            for item in elements[1:]:\n",
    "                index, value = item.split(':')\n",
    "                feature_vector[int(index)] = float(value)\n",
    "            features.append(feature_vector)\n",
    "\n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(train_file, test_file):\n",
    "    labels_train, features_train = parse_libsvm_file(train_file)\n",
    "    labels_test, features_test = parse_libsvm_file(test_file)\n",
    "\n",
    "    num_samples = len(labels_train)\n",
    "    num_features =  max(max(max(sample.keys()) for sample in features_train), max(max(test.keys()) for test in features_test))\n",
    "\n",
    "     #weights = [w0 w1......wn] where n = num_features\n",
    "    w = np.zeros(num_features+1)\n",
    "\n",
    "\n",
    "    #first create a matrix with just features\n",
    "    X_train = np.zeros((num_samples, num_features))\n",
    "    for i, sample in enumerate(features_train):\n",
    "        for j, value in sample.items():\n",
    "            X_train[i, j-1] = value\n",
    "    \n",
    "    #join this matrix with a column of just ones for bias\n",
    "    X_train = np.c_[np.ones(num_samples), X_train]\n",
    "\n",
    "\n",
    "    #repeat for X_test\n",
    "    X_test = np.zeros((len(labels_test), num_features))\n",
    "    for i, sample in enumerate(features_test):\n",
    "        for j, value in sample.items():\n",
    "            X_test[i, j-1] = value\n",
    "    \n",
    "    #join this matrix with a column of just ones for bias\n",
    "    X_test = np.c_[np.ones(len(labels_test)), X_test]\n",
    "\n",
    "    y_train = np.array(labels_train)\n",
    "    y_test = np.array(labels_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot product of two vectors a and b, a dot b\n",
    "def dot_product(a, b):\n",
    "    res = 0\n",
    "    for i in range(len(a)):\n",
    "        res+= a[i]*b[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+pow(e, -z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define probability over vector x[i] and true val y[i] where i is one sample\n",
    "def prob(w, x_n, y_n):\n",
    "    return sigmoid(y_n*dot_product(w, x_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient of loss with respect to weights, for some ith sample\n",
    "def delta_loss(w, x_n, y_n):\n",
    "    return (1-prob(w, x_n, y_n))*y_n*x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "def xent(y_prob, y):\n",
    "    xent = 0\n",
    "    for i in range(len(y)):\n",
    "        xent -= y[i]*log2(y_prob[i])\n",
    "    return xent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([1,-1,1])\n",
    "v = np.array([0.8,0.2,0.7])\n",
    "xent(v, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_and_xent(X, y, w):\n",
    "    sample_size = len(y)\n",
    "    y_prob = (np.array([sigmoid(dot_product(w,X[j])) for j in range(sample_size)]))\n",
    "    labelizer = (lambda t: 1 if t>0.5 else -1)\n",
    "    labelizer = np.vectorize(labelizer)\n",
    "\n",
    "    #get predicted labels\n",
    "    y_pred = labelizer(y_prob)\n",
    "\n",
    "    #calculate accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, j in zip(y, y_pred):\n",
    "        if i==j:\n",
    "            correct+=1\n",
    "        total +=1\n",
    "    \n",
    "    accuracy = float(correct/total)\n",
    "\n",
    "    #calculate cross entropy loss\n",
    "    xent_val = xent(y_prob, y)\n",
    "\n",
    "    return accuracy, xent_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_pass(X_train, y_train, X_test, y_test, w,learning_rate):\n",
    "    sample_size = len(y_train)\n",
    "    for i in range(sample_size):\n",
    "        w += learning_rate*delta_loss(w, X_train[i], y_train[i])\n",
    "    \n",
    "    #after weight updated, calculate the probability or sigmoid value\n",
    "    #first \n",
    "    train_accuracy, train_xent = get_accuracy_and_xent(X_train, y_train, w)\n",
    "    test_accuracy, test_xent = get_accuracy_and_xent(X_test, y_test, w)\n",
    "\n",
    "    print(f\"TRAIN accuracy {train_accuracy:.3f} xent {train_xent:.3f}   TEST accuracy {test_accuracy:.3f} xent {test_xent:.3f}\")\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    iterations = 10\n",
    "    learning_rate = 0.001\n",
    "    X_train, y_train, X_test, y_test, w = load('a7a.train', 'a7a.test')\n",
    "    for iter in range(iterations):\n",
    "        w = train_one_pass(X_train, y_train, X_test, y_test, w,learning_rate)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
